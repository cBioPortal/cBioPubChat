# ğŸ§¬ cBioPubChat

**Ask questions. Explore cancer publications. Discover insights.**

> âš ï¸ _This project is a **work in progress** being developed for the **cBioPortal Hackathon 2025**._

cBioPubChat is an AI-powered chatbot designed to help researchers, clinicians, and enthusiasts interact with publications from cBioPortal studies. By combining vector search with large language models, the chatbot can:

- Retrieve the most relevant studies based on a user question
- Summarize the key findings from those studies
- Provide direct links to the studies in [cBioPortal](https://www.cbioportal.org/)

## Usage

### Environment setup
```shell
# Run init script to setup a python venv and install requirements
source scripts/init_env.sh

# Everytime you start your ide/terminal, source the venv to use correct dependencies
source venv/bin/activate

# Download the embeddings
./scripts/init_db.sh
```

### Run test script
To test your environment, export your OpenAI API Key and run the test script.
```shell
py tests/env.py

# If all is successful, the test script should put a smile on your face!
```

### Start app
```shell
chainlit run app.py -w
```

## Sample Use Case

> _â€œWhich pathways are most commonly altered in ovarian cancer?â€_

cBioPubChat will:
- Search all study publication text using embedding similarity
- Summarize relevant findings with an LLM
- Provide links to those studies in cBioPortal

## Planned Tech Stack

- **[Chainlit](https://github.com/Chainlit/chainlit)** â€“ Interactive chat UI
- **[LangChain](https://www.langchain.com/)** â€“ LLM pipeline & orchestration
- **[ChromaDB](https://www.trychroma.com/)** â€“ Vector store for publication embeddings
- **Python** 3.10+
- **LLMs** â€“ OpenAI or other LangChain-compatible providers

## Planned Project Structure
```shell
cBioPubChat/
â”œâ”€â”€ app/                          # Chainlit app frontend and config
â”‚   â”œâ”€â”€ main.py                   # Chainlit entrypoint (UI + LangChain agent)
â”‚   â””â”€â”€ config.toml               # Chainlit config (title, theme, etc.)
â”œâ”€â”€ backend/                      # Core logic: embeddings, indexing, QA
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ parse_publications.py # PDF, HTML, or plain text loader
â”‚   â”‚   â”œâ”€â”€ embed_and_store.py    # Convert text â†’ embeddings â†’ store in ChromaDB
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ qa/
â”‚   â”‚   â”œâ”€â”€ query_engine.py       # Embedding search + summarization pipeline
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                         # Raw and processed publication data
â”‚   â”œâ”€â”€ raw/                      # Raw PDFs or metadata
â”‚   â””â”€â”€ processed/                # Text chunks or cleaned files
â”œâ”€â”€ chroma/                       # Local ChromaDB index directory (auto-created)
â”œâ”€â”€ notebooks/                    # (Optional) Jupyter notebooks for exploration
â”‚   â””â”€â”€ analysis.ipynb
â”œâ”€â”€ tests/                        # Unit and integration tests
â”‚   â”œâ”€â”€ test_ingest.py
â”‚   â”œâ”€â”€ test_query.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/                      # Convenience scripts (e.g., bootstrap)
â”‚   â””â”€â”€ run_ingest.sh
â”œâ”€â”€ .env                          # API keys, secrets (ignored by git)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt              # Pip dependencies
```